{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data for inference\n",
    "This notebook contains the pipeline for downloading and preparing the data for inference.\n",
    "The data for training can also be downloaded and prepared using this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVfO2f-dHIV0"
   },
   "outputs": [],
   "source": [
    "import satsearch\n",
    "import os\n",
    "import rasterio\n",
    "import pyproj\n",
    "from osgeo import gdal\n",
    "import requests\n",
    "import tqdm\n",
    "import geopandas as gpd\n",
    "import utils\n",
    "import numpy as np\n",
    "from rasterio.merge import merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9.604728, 52.305911, 9.91856, 52.453728)\n"
     ]
    }
   ],
   "source": [
    "# select the city name \n",
    "city_name = \"Hannover\"\n",
    "\n",
    "# getting bbox coordinates from multipolygon in administrative boundaries geojson file\n",
    "filepath_json = f\"path/{city_name}/{city_name}_ab.geojson\"\n",
    "coords = utils.get_bbox_from_geojson(filepath_json)\n",
    "print(coords) # coordinates in WGS84 used for querying the STAC\n",
    "\n",
    "# getting coordinates from geojson\n",
    "polygon_gdf = gpd.read_file(filepath_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict with city names and their respective bboxes, Sentinel-2 tile ids and EPSG coordinate codes\n",
    "# follow the dict structure to add/change cities\n",
    "city_dicts = {\n",
    "            \"Bremen\": {\n",
    "                \"bbox\": [8.481735, 53.011021, 8.990913, 53.597327],\n",
    "                \"tile_id\": \"32UMD\",\n",
    "                \"epsg\": 32632},\n",
    "            \"Bielefeld\": {\n",
    "                \"bbox\": [8.377677, 51.91497, 8.663542, 52.114833],\n",
    "                \"tile_id\": \"32UMC\",\n",
    "                \"epsg\": 32632},\n",
    "            \"Essen\": {\n",
    "                \"bbox\": [6.894508, 51.347413, 7.136842, 51.534127],\n",
    "                \"tile_id\": \"32ULC\",\n",
    "                \"epsg\": 32632},\n",
    "            \"Duesseldorf\": {\n",
    "                \"bbox\": [6.689823, 51.124394, 6.939965, 51.351446],\n",
    "                \"tile_id\": \"32ULB\",\n",
    "                \"epsg\": 32632},\n",
    "            \"Cologne\": {\n",
    "                \"bbox\": [6.77256, 50.830434, 7.162043, 51.084961], \n",
    "                \"tile_id\": \"31UGS\",\n",
    "                \"epsg\": 32631},\n",
    "            \"Frankfurt\": {\n",
    "                \"bbox\": [8.472633, 50.015574, 8.800535, 50.226257],\n",
    "                \"tile_id\": \"32UMA\",\n",
    "                \"epsg\": 32632},\n",
    "            \"Nuremberg\": {\n",
    "                \"bbox\": [10.987928, 49.331937, 11.21357, 49.540333],\n",
    "                \"tile_id\": \"32UPV\",\n",
    "                \"epsg\": 32632},\n",
    "            \"Dresden\": {\n",
    "                \"bbox\": [13.579721, 50.975184, 13.965849, 51.177704],\n",
    "                \"tile_id\": \"33UVS\",\n",
    "                \"epsg\": 32633},\n",
    "            \"Leipzig\": {\n",
    "                \"bbox\": [12.236779, 51.238154, 12.542607, 51.448067],\n",
    "                \"tile_id\": [\"32UQB\", \"32UQC\"],\n",
    "                \"epsg\": 32632},\n",
    "            \"Hannover\": {\n",
    "                \"bbox\": [9.604728, 52.305911, 9.91856, 52.453728],\n",
    "                \"tile_id\": \"32UND\",\n",
    "                \"epsg\": 32632},\n",
    "            \"Munich\": {\n",
    "                \"bbox\": [11.360877, 48.061554, 11.723083, 48.248146],\n",
    "                \"tile_id\": \"32UPU\",\n",
    "                \"epsg\": 32632},\n",
    "            \"Berlin\": {\n",
    "                \"bbox\": [13.088333, 52.338242, 13.760469, 52.675379],\n",
    "                \"tile_id\": [\"33UVU\", \"33UUU\"],\n",
    "                \"epsg\": 32633},\n",
    "            \"Hamburg\": {\n",
    "                \"bbox\": [9.734365, 53.39507, 10.325959, 53.738472],\n",
    "                \"tile_id\": [\"32UNE\"],\n",
    "                \"epsg\": 32632},\n",
    "            \"Dortmund\": {\n",
    "                \"bbox\": [7.302311, 51.41558, 7.637933, 51.59952],\n",
    "                \"tile_id\": [\"32ULC\"],\n",
    "                \"epsg\": 32632},\n",
    "            \"Stuttgart\": {\n",
    "                \"bbox\": [9.038994, 48.689956, 9.315387, 48.867249],\n",
    "                \"tile_id\": [\"32UNV\"],\n",
    "                \"epsg\": 32632},\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterizing the administrative boundaries geojson\n",
    "rasterized_json_filepath, _ = os.path.splitext(filepath_json)\n",
    "rasterized_json_filepath = f\"{rasterized_json_filepath}.{\".tif\".lstrip('.')}\"\n",
    "utils.reproject_and_rasterize(filepath_json, f\"EPSG:{city_dicts[city_name][\"epsg\"]}\", rasterized_json_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating directories for the selected city\n",
    "dir_list = [\"cogs\", \"composites\", \"tiles\"]\n",
    "path = \"root/path\"  \n",
    "\n",
    "for dir in dir_list:\n",
    "    if not os.path.exists(os.path.join(path, city_name, dir)):\n",
    "        os.makedirs(os.path.join(path, city_name, dir))\n",
    "        print(\"Directory created!\")\n",
    "    else:\n",
    "        print(\"Directory already exists! Check city name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching the STAC catalogue for the selected AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbox search: 120 items\n"
     ]
    }
   ],
   "source": [
    "bounding_box = city_dicts[city_name][\"bbox\"]\n",
    "\n",
    "search = satsearch.Search(\n",
    "    bbox = [i for i in bounding_box],\n",
    "    datetime='2018-05-01/2018-09-30',\n",
    "    collections=['sentinel-s2-l2a-cogs'],\n",
    "    url='https://earth-search.aws.element84.com/v0' # Element84 public STAC catalogue\n",
    "    )\n",
    "\n",
    "print('bbox search: %s items' % search.found())\n",
    "\n",
    "items = search.items()\n",
    "#print(items.summary(['date', 'id', 'eo:cloud_cover']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*During this step it is recommended to manually download each product to check for artifacts and clouds above AOI*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkLtA2NidFxh"
   },
   "outputs": [],
   "source": [
    "bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "links_dict = {}\n",
    "for i in items:\n",
    "  if i['eo:cloud_cover'] <= 5.0 and i['eo:cloud_cover'] != 0: \n",
    "    for tile_id in city_dicts[city_name][\"tile_id\"]:\n",
    "      if tile_id in i.id:\n",
    "        links_dict[i.id] = []\n",
    "        for band in bands:\n",
    "          links_dict[i.id].append(i.asset(band)[\"href\"])\n",
    "      else: \n",
    "        continue\n",
    "  else:\n",
    "    continue\n",
    "print(\"Number of products:\", len(links_dict.keys()))\n",
    "links_dict # returning the dict of links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6Bw8lWbc5WM"
   },
   "outputs": [],
   "source": [
    "# filtering the links dict for chosen products\n",
    "# products are chosen after manually downloading and inspecting them for cloud cover and artifacts\n",
    "chosen_products_dict = {\"Bremen\": \"S2B_32UMD_20180629_0_L2A\",\n",
    "                        \"Bielefeld\": \"S2A_32UMC_20180806_0_L2A\",\n",
    "                        \"Essen\": \"S2A_32ULC_20180707_0_L2A\",\n",
    "                        \"Duesseldorf\": \"S2A_32ULB_20180707_0_L2A\",\n",
    "                        \"Cologne\": \"S2B_31UGS_20180722_0_L2A\",\n",
    "                        \"Frankfurt\": \"S2B_32UMA_20180818_0_L2A\",\n",
    "                        \"Nuremberg\": \"S2A_32UPV_20180820_0_L2A\",\n",
    "                        \"Dresden\": \"S2B_33UVS_20180514_0_L2A\",\n",
    "                        \"Leipzig\": [\"S2B_32UQB_20180703_0_L2A\", \"S2B_32UQC_20180703_0_L2A\"], # 2 products because AOI is covered by 2 products\n",
    "                        \"Hannover\": \"S2A_32UND_20180724_0_L2A\",\n",
    "                        \"Munich\": \"S2A_32UPU_20180731_0_L2A\",\n",
    "                        \"Berlin\": [\"S2A_33UVU_20180909_0_L2A\", \"S2A_33UUU_20180909_0_L2A\"], # 2 products because AOI is covered by 2 products\n",
    "                        \"Hamburg\": \"S2A_32UNE_20180505_0_L2A\",\n",
    "                        \"Dortmund\": \"S2A_32ULC_20180607_0_L2A\",\n",
    "                        \"Stuttgart\": \"S2A_32UNV_20180505_0_L2A\",\n",
    "                        }\n",
    "\n",
    "# creating the dict of links for each product band\n",
    "links_dict = {key:value for (key, value) in links_dict.items() if key in chosen_products_dict[city_name]}\n",
    "links_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjmCPklUeelN"
   },
   "source": [
    "### Downloading bands rasters and cropping them to the AOI (bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = utils.get_bbox_geotiff(rasterized_json_filepath)\n",
    "bbox_epsg = [coords[0], coords[3], coords[2], coords[1]]\n",
    "print(bbox_epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6_4gq15zdpK"
   },
   "outputs": [],
   "source": [
    "# function to crop one raster\n",
    "def crop_one_raster (filepath, bounding_box, delete=False):\n",
    "  window = (bounding_box[0], bounding_box[1], bounding_box[2], bounding_box[3])\n",
    "  new_name = filepath[:-4] + '_cropped.tif'\n",
    "  print(new_name)\n",
    "  ds = gdal.Open(filepath)\n",
    "  gdal.Translate(new_name, filepath, projWin = window)\n",
    "  # deletion may not work in some systems, use with caution\n",
    "  if delete:\n",
    "    # rewriting file to 0 bytes\n",
    "    open(filepath, 'w').close()\n",
    "    # moving the 0-bytes file to bin\n",
    "    os.remove(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72CLSYCgdusn"
   },
   "outputs": [],
   "source": [
    "# downloading and cropping rasters\n",
    "download_path = f'path/{city_name}/cogs/'\n",
    "\n",
    "# creating directories if they don't exist\n",
    "if not os.path.exists(download_path):\n",
    "    os.makedirs(download_path)\n",
    "\n",
    "for item in links_dict:\n",
    "  filename = item\n",
    "  for link, band in zip(links_dict[item], bands):\n",
    "    filepath = os.path.join(download_path, f\"{filename}_{band}.tif\")\n",
    "    r = requests.get(link, stream = True)\n",
    "    print(filepath)\n",
    "    with open(filepath, \"wb\") as file:\n",
    "      for block in tqdm.tqdm(r.iter_content(chunk_size = 1024)):\n",
    "        if block:\n",
    "          file.write(block)\n",
    "    input_path = filepath\n",
    "    crop_one_raster(input_path, bbox_epsg, delete=False) # if delete=True original files are deleted\n",
    "\n",
    "# deleting uncropped rasters\n",
    "list_files = os.listdir(download_path)\n",
    "list_files = [i for i in os.listdir(download_path) if \"cropped\" not in i]\n",
    "for i in list_files:\n",
    "    os.remove(os.path.join(download_path, i))\n",
    "\n",
    "print(\"Download finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zk93k2N2SZo"
   },
   "source": [
    "### Creating all-bands composite\n",
    "\n",
    "If not using automatic deletion for crop_one_raster function, make sure the downloaded original files are deleted, otherwise the following algorithm may results in errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKLMU8th2dzA",
    "outputId": "63ce7ed4-baf6-406f-eb2b-a47d17f5b295"
   },
   "outputs": [],
   "source": [
    "# creating dict of filenames in each band folder\n",
    "filepaths_all = download_path\n",
    "filepath_composites = f\"path/{city_name}/composites/\"\n",
    "\n",
    "if not os.path.exists(filepath_composites):\n",
    "    os.makedirs(filepath_composites)\n",
    "\n",
    "# getting the list of files and sorting it\n",
    "files_list = os.listdir(download_path)\n",
    "if len(files_list) == 12:\n",
    "  # sorting list (so the band 8A is after band 8)\n",
    "  last_element = files_list.pop()\n",
    "  files_list.insert(8, last_element)\n",
    "\n",
    "  counter = 0\n",
    "  opened_bands = []\n",
    "  # making composites\n",
    "  for i in range(0, len(files_list)):\n",
    "    with rasterio.open(os.path.join(filepaths_all, files_list[i]), 'r') as src:\n",
    "        if i == 1:\n",
    "          band2_profile = src.profile\n",
    "          band2_profile.update({\"count\": 12}) # increasing the band count to 12\n",
    "        opened_bands.append(src.read(1))\n",
    "\n",
    "  img_path = os.path.join(filepath_composites, f\"{files_list[0][:24]}_composite.tif\")\n",
    "\n",
    "  with rasterio.open(img_path, 'w', **band2_profile) as img:\n",
    "    counter = 1\n",
    "    for band in opened_bands:\n",
    "      img.write(band, counter)\n",
    "      counter += 1\n",
    "\n",
    "  # rewriting the geotiff to match the administrative boundaries\n",
    "  utils.modify_geotiff_with_mask(img_path, rasterized_json_filepath, img_path)\n",
    "\n",
    "\n",
    "# if folder contains more than 2 products\n",
    "if len(files_list) > 12:\n",
    "  # sorting lists and splitting them to list of lists\n",
    "  list_of_files_list = []\n",
    "  counter_ = 0\n",
    "  for idx in range(1, int(len(files_list) / 12) + 1):\n",
    "    modifier_1 = 11 + (counter_ * 12)\n",
    "    modifier_2 = 8 + (counter_ * 12)\n",
    "    last_element = files_list.pop(modifier_1)\n",
    "    files_list.insert(modifier_2, last_element)\n",
    "    counter_ += 1\n",
    "    list_of_files_list.append(files_list[(modifier_1 - 11):(modifier_1 + 1)])\n",
    "  \n",
    "  # looping over products\n",
    "  for files_list in list_of_files_list:\n",
    "      counter = 0\n",
    "      opened_bands = []\n",
    "      for i in range(0, len(files_list)):\n",
    "        with rasterio.open(os.path.join(filepaths_all, files_list[i]), 'r') as src:\n",
    "            if i == 1:\n",
    "              band2_profile = src.profile\n",
    "              band2_profile.update({\"count\": 12}) # increasing the layer count to 12\n",
    "            opened_bands.append(src.read(1))\n",
    "\n",
    "      img_path = os.path.join(filepath_composites, f\"{files_list[0][:24]}_composite.tif\")\n",
    "\n",
    "      with rasterio.open(img_path, 'w', **band2_profile) as img:\n",
    "        counter = 1\n",
    "        for band in opened_bands:\n",
    "          img.write(band, counter)\n",
    "          counter += 1\n",
    "\n",
    "print(\"Composites created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging composites together if there's more than one file in the composites folder \n",
    "list_comps = [i for i in os.listdir(filepath_composites) if \"merged\" not in i]\n",
    "if len(list_comps) > 1:\n",
    "    composites_list = []\n",
    "    for comp in list_comps:\n",
    "        src = rasterio.open(os.path.join(filepath_composites, comp))\n",
    "        composites_list.append(src)\n",
    "        out_meta = src.meta.copy()\n",
    "    \n",
    "    merged_comp, out_transform = merge(composites_list)\n",
    "\n",
    "    for src in composites_list:\n",
    "        src.close()\n",
    "\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                \"height\": merged_comp.shape[1],\n",
    "                \"width\": merged_comp.shape[2],\n",
    "                \"transform\": out_transform,\n",
    "                #\"crs\": crs\n",
    "                })\n",
    "\n",
    "    path_merged_comp = os.path.join(filepath_composites, list_comps[0])\n",
    "    path_merged_comp, _ = os.path.splitext(path_merged_comp)\n",
    "    path_merged_comp = f\"{path_merged_comp}_merged.{\".tif\".lstrip('.')}\"\n",
    "\n",
    "    with rasterio.open(path_merged_comp, \"w\", **out_meta) as dst:\n",
    "        dst.write(merged_comp)\n",
    "\n",
    "    # deleting original composites\n",
    "    list_files = os.listdir(filepath_composites)\n",
    "    list_files = [i for i in os.listdir(filepath_composites) if \"merged\" not in i]\n",
    "    for i in list_files:\n",
    "        os.remove(os.path.join(filepath_composites, i))\n",
    "    \n",
    "    list_files = os.listdir(filepath_composites)\n",
    "    img_path = os.path.join(filepath_composites, list_files[0])\n",
    "    utils.modify_geotiff_with_mask(img_path, rasterized_json_filepath, img_path)\n",
    "    print(\"Processing finished!\")\n",
    "\n",
    "else:\n",
    "    print(\"Only 1 composite is present in the folder! Nothing was done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMSgExIakqRU"
   },
   "source": [
    "## Tiling the composites\n",
    "Splitting composites to tiles is necessary because the model only takes images of size (128, 128, 12). If the model input size is changed, the size should also be changed in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNvtAhnf-Too"
   },
   "outputs": [],
   "source": [
    "# Defining the cropping function\n",
    "def get_tiles(ds, tile_width, tile_height, overlap=0, check_zeroes=True):\n",
    "    \"\"\"\n",
    "    Yields rasterio.window and the respective transform object.\n",
    "    Args:\n",
    "        ds: rasterio-opened datasource\n",
    "        tile_width: width of the tile to yield\n",
    "        tile_height: height of the tile to yield\n",
    "        overlap: tile overlap (use 0 for inference data preparation)\n",
    "        check_zeroes (bool): if True, omits every tile that consists only of zeroes. useful when AOI is not of rectangular shape\n",
    "    \"\"\"\n",
    "    ncols, nrows = ds.meta['width'], ds.meta['height']\n",
    "    xstep = tile_width - overlap\n",
    "    ystep = tile_height - overlap\n",
    "    for x in range(0, ncols, xstep):\n",
    "        for y in range(0, nrows, ystep):\n",
    "            window = rasterio.windows.Window(x, y, tile_width, tile_height)\n",
    "            if check_zeroes:\n",
    "                all_zero = np.all(src.read(1, window=window) == 0)\n",
    "                if all_zero:\n",
    "                    continue\n",
    "                else:\n",
    "                    transform = rasterio.windows.transform(window, ds.transform)\n",
    "                    yield window, transform\n",
    "            else:\n",
    "                transform = rasterio.windows.transform(window, ds.transform)\n",
    "                yield window, transform\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6KW_duJKCWEs",
    "outputId": "bee79709-320d-441c-ae72-25fd3e1cea49"
   },
   "outputs": [],
   "source": [
    "# batch tiling the images\n",
    "\n",
    "# set tiling options\n",
    "tile_width = 128 \n",
    "tile_height = 128 \n",
    "overlap = 0 \n",
    "\n",
    "in_path = f\"path/{city_name}/composites\" # filepath to composites\n",
    "out_path = f\"path/{city_name}/tiles/\" # filepath to output tiles\n",
    "\n",
    "if not os.path.exists(in_path):\n",
    "    os.makedirs(in_path)\n",
    "\n",
    "output_filename = '{}_{}_{}.tif'\n",
    "input_filenames = os.listdir(in_path)\n",
    "\n",
    "for input_filename in input_filenames:\n",
    "  with rasterio.open(os.path.join(in_path, input_filename)) as src:\n",
    "    metadata = src.meta.copy()\n",
    "\n",
    "    for window, transform in get_tiles(src, tile_width, tile_height, overlap):\n",
    "        metadata['transform'] = transform\n",
    "        metadata['width'], metadata['height'] = window.width, window.height\n",
    "        out_filepath = os.path.join(out_path, output_filename.format(input_filename[:-17], window.col_off, window.row_off))\n",
    "\n",
    "        with rasterio.open(out_filepath, 'w', **metadata) as dst:\n",
    "            dst.write(src.read(window=window))\n",
    "    print(out_filepath)\n",
    "print(\"Tiling finished!\")\n",
    "print(len(os.listdir(out_path)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sat-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
